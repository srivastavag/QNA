# ğŸ§  Document-Based Q&A System (FastAPI + FAISS + LLaMA3)

This is a lightweight, retrieval-augmented question-answering (RAG) application that answers user questions based **only on the information present in uploaded documents** (PDF or text).

Built with:
- ğŸ§ª FastAPI (backend server)
- ğŸ” SentenceTransformer embeddings + FAISS for semantic search
- ğŸ¦™ LLaMA3 (via Ollama) for natural language reasoning and answers
- ğŸ“„ Document ingestion with paragraph chunking
- â˜ï¸ Ready for Render.com deployment

---

## ğŸš€ Features

- **Strict fact-based answering**: No hallucinations
- **Chunk-based document search** using sentence embeddings
- **PDF and TXT document support**
- **Handles multiple documents and topics**
- **Switchable LLM backend** (local llama3 or cloud APIs)

---

## ğŸ“ Folder Structure

â”œâ”€â”€ app/
â”‚ â”œâ”€â”€ main.py # FastAPI app
â”‚ â”œâ”€â”€ qa_engine.py # Embedding, chunking, LLM prompt logic
â”‚ â””â”€â”€ utils.py # PDF/TXT reading, chunking
â”œâ”€â”€ docs/ # Folder for your document files
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ render.yaml # Render deployment config
â””â”€â”€ README.md